{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.vision import *\nimport os\nfrom PIL import Image\nfrom skimage import io, transform\nimport torchvision.transforms.functional as TF\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.io import loadmat\nfrom skimage import io as sk_io\n\nplt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams['image.cmap'] = 'gray'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib\nmatplotlib.use(\"Agg\")\n\n# import the necessary packages\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import SGD\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import classification_report\nimport matplotlib.pyplot as plt\nimport numpy as np\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ls \"/kaggle/input/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled/\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport keras\nclass DataGenerator(keras.utils.Sequence):\n    def __init__(self, root, valid_th=0, phase='train' , batch_size=33, dim=(152,152), n_channels=3 ,shuffle=True):\n    \n        folder_list = sorted(os.listdir(root))\n        image_list=[]\n\n        label_path='/kaggle/input/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled'# for labels\n        label_list=list(np.array(sorted(os.listdir(label_path))))#[(train_pro[0]-1)])\n        self.label_dict={label_list[i]:i for i in range(len(label_list))}\n\n        for i in range(len(folder_list)):\n            folder_pic=os.path.join(root,folder_list[i])\n            list_pic = sorted(os.listdir(folder_pic))\n            for j in range(len(list_pic)):\n                img=os.path.join(folder_pic,list_pic[j])\n                image_list.append(img)  \n\n                    \n        self.image_list = image_list\n        self.root = root\n        self.transform = transform\n        self.batch_size = batch_size\n        self.dim=dim\n        self.n_channels=n_channels\n\n    def __len__(self):\n        return len(self.image_list)//self.batch_size\n    \n    \n    def __data_generation(self, list_IDs_temp):\n        \n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        y = []\n\n        # Generate data\n        for i, ID in enumerate(list_IDs_temp):\n            image = Image.open(list_IDs_temp[i]).convert('RGB').resize((152,152),Image.BICUBIC)\n            image = np.array(image)\n            image = image[None,:,:,:]\n            X[i,] = image\n    \n            \n            label = Path(list_IDs_temp[i]).stem\n            num = str(int(label[-4:]))\n            name = label[:-4]\n            label = name+num\n            y.append(label)\n            \n#             X=X.astype('float32'); X=X/255.0\n#             y=y.astype('float32'); y=y/255.0\n            #keras.utils.to_categorical(y, num_classes=self.n_classes)\n        return X, y\n\n    def __getitem__(self, idx):\n        \n        list_IDs_temp = self.image_list[idx*self.batch_size:(idx+1)*self.batch_size]\n        X, y = self.__data_generation(list_IDs_temp)\n        return X, y\n    \n    def shuffle(self):\n        import random\n        random.shuffle(self.image_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"13233/33","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(img_gen.image_list)\nlen(img_gen)\n401*33","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nroot='/kaggle/input/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled'\nimg_gen = DataGenerator(root, phase='train')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom pathlib import Path\nimport keras\nfrom keras.models import Model, Sequential\nfrom keras.layers import Convolution2D, LocallyConnected2D, MaxPooling2D, Flatten, Dense, Dropout\nimport matplotlib.pyplot as plt\nimport cv2\nfrom keras.utils import plot_model\nimport numpy as np\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\tbase_model = Sequential()\n\tbase_model.add(Convolution2D(32, (11, 11), activation='relu', name='C1', input_shape=(152, 152, 3)))\n\tbase_model.add(MaxPooling2D(pool_size=3, strides=2, padding='same', name='M2'))\n\tbase_model.add(Convolution2D(16, (9, 9), activation='relu', name='C3'))\n\tbase_model.add(LocallyConnected2D(16, (9, 9), activation='relu', name='L4'))\n\tbase_model.add(LocallyConnected2D(16, (7, 7), strides=2, activation='relu', name='L5') )\n\tbase_model.add(LocallyConnected2D(16, (5, 5), activation='relu', name='L6'))\n\tbase_model.add(Flatten(name='F0'))\n\tbase_model.add(Dense(4096, activation='relu', name='F7'))\n\tbase_model.add(Dropout(rate=0.5, name='D0'))\n\tbase_model.add(Dense(8631, activation='softmax', name='F8'))\n    \n\tbase_model.load_weights('/kaggle/input/my-dataset-for-test/VGGFace2_DeepFace_weights_val-0.9034.h5')\n\t#print(base_model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"deepface_model = Model(inputs=base_model.layers[0].input, outputs=base_model.layers[-3].output)\n#print(deepface_model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\n\nemb_list=[]\nname_list=[]\n\nfor inc, data in tqdm(enumerate(img_gen)):\n    img = data[0]\n    label = data[1]\n    emb = deepface_model.predict(img)\n    #emb = emb.detach().numpy()\n    label = list(label)\n    for i in range(len(label)):\n        emb_list.append(emb[i])\n        name_list.append(label[i])\n\n\nembeddings={}\nfor i in range(len(name_list)):\n    embeddings[name_list[i]]=emb_list[i]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(list(embeddings.items()),columns = ['name','emb']) \ndf.to_pickle('pickle')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ndf = pd.read_pickle('/kaggle/input/pretrained-models/pickle')\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings = dict(zip(df.column1, df.column2))\n\nembeddings.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def loadPairs(pairsFname):\n    print(\"  + Reading pairs.\")\n    pairs = []\n    with open(pairsFname, 'r') as f:\n        for line in f.readlines()[1:]:\n            #line = line[:-1]\n            pair = line.strip().split(\",\")\n            if len(pair[3]) == 0:\n                del pair[3]\n            #print(pair)\n            pairs.append(pair)\n    assert(len(pairs) == 6000)\n    return np.array(pairs)\n\npair = loadPairs('/kaggle/input/lfw-dataset/pairs.csv')\npair.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getEmbeddings(pair, embeddings):\n    if len(pair) == 3:\n        name1 = \"{}_{}\".format(pair[0], pair[1])\n        name2 = \"{}_{}\".format(pair[0], pair[2])\n        actual_same = True\n    elif len(pair) == 4:\n        name1 = \"{}_{}\".format(pair[0], pair[1])\n        name2 = \"{}_{}\".format(pair[2], pair[3])\n        actual_same = False\n    else:\n        raise Exception(\n            \"Unexpected pair length: {}\".format(len(pair)))\n\n    (x1, x2) = (embeddings[name1], embeddings[name2])\n    return (x1, x2, actual_same)\n\ndef getDistances(embeddings, pairs):\n    list_dist = []\n    y_true = []\n    for pair in pairs:\n        (x1, x2, actual_same) = getEmbeddings(pair, embeddings)\n        diff = x1 - x2\n        dist = np.dot(diff.T, diff)\n        list_dist.append(dist)\n        y_true.append(actual_same)\n    return np.asarray(list_dist), np.array(y_true)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\nimport numpy as np\nimport pandas as pd\nfrom scipy.interpolate import interp1d\n#from sklearn.cross_validation import KFold\nfrom sklearn.metrics import accuracy_score\n\ndef findBestThreshold(thresholds, embeddings, pairsTrain):\n    bestThresh = bestThreshAcc = 0\n    distances, y_true = getDistances(embeddings, pairsTrain)\n    for threshold in thresholds:\n        y_predlabels = np.zeros(y_true.shape)\n        y_predlabels[np.where(distances < threshold)] = 1\n        accuracy = accuracy_score(y_true, y_predlabels)\n        if accuracy >= bestThreshAcc:\n            bestThreshAcc = accuracy\n            bestThresh = threshold\n        else:\n            # No further improvements.\n            return bestThresh\n    return bestThresh\nthresholds = np.array([0.5,0.6,0.7,0.8,0.9,1.0,1.1,1.2,1.3,1.4,1.5])\nbestThresh = findBestThreshold(thresholds, embeddings, pair)\nbestThresh","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\ndef evalThresholdAccuracy(embeddings, pairs, threshold):\n    distances, y_true = getDistances(embeddings, pairs)\n    y_predict = np.zeros(y_true.shape)\n    y_predict[np.where(distances < threshold)] = 1\n    y_true = np.array(y_true)\n    accuracy = accuracy_score(y_true, y_predict)\n    return accuracy#, pairs[np.where(y_true != y_predict)]\n\nacc = evalThresholdAccuracy(embeddings, pair, threshold=1.5)\nacc","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"def writeROC(fname, thresholds, embeddings, pairsTest):\n    with open(fname, \"w\") as f:\n        f.write(\"threshold,tp,tn,fp,fn,tpr,fpr\\n\")\n        tp = tn = fp = fn = 0\n        for threshold in thresholds:\n            tp = tn = fp = fn = 0\n            for pair in pairsTest:\n                (x1, x2, actual_same) = getEmbeddings(pair, embeddings)\n                diff = x1 - x2\n                dist = np.dot(diff.T, diff)\n                predict_same = dist < threshold\n\n                if predict_same and actual_same:\n                    tp += 1\n                elif predict_same and not actual_same:\n                    fp += 1\n                elif not predict_same and not actual_same:\n                    tn += 1\n                elif not predict_same and actual_same:\n                    fn += 1\n\n            if tp + fn == 0:\n                tpr = 0\n            else:\n                tpr = float(tp) / float(tp + fn)\n            if fp + tn == 0:\n                fpr = 0\n            else:\n                fpr = float(fp) / float(fp + tn)\n            f.write(\",\".join([str(x)\n                              for x in [threshold, tp, tn, fp, fn, tpr, fpr]]))\n            f.write(\"\\n\")\n            if tpr == 1.0 and fpr == 1.0:\n                # No further improvements.\n                f.write(\",\".join([str(x)\n                                  for x in [4.0, tp, tn, fp, fn, tpr, fpr]]))\n                return","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fname='roc_info'\nwriteROC(fname, thresholds, embeddings, pairsTest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rocData = pd.read_csv(\"roc_info\")\nfpr, tpr = rocData['fpr'], rocData['tpr']\nplt.plot(fpr,tpr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}